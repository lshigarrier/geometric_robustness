name : jacobian/jac_1
model : 00030.pt
seed : 1

train : True
load : False
adv_test : False
reg : True

# model

channels1 : 32
channels2 : 64
hidden : 128

# training

epochs : 10
batch_size : 32
test_batch_size : 32
learning_rate : 0.01

# e.g., eps_inf = 0.3 => eps_l2 = sqrt(784)*eps_inf = 28*0.3 = 8.4
epsilon : 8.4
eta : 0.1

verbose : True
log_interval : 100
save_step : 1

# testing

testing_batch_size : 1
loader : train

# attack

perturbation_type : linf
budget : 0.1
alpha : 0.01
max_iter : 40

-----------------------------------------------------------------------------------------------------

# light_train_loader

## epoch 10

### budget 0.1

Using cpu
Using testing batch size for test loader
Using testing batch size for train loader
Loading weights
Initialization done
Start testing
Using light train loader
Test: 0/1000 (0%)	Loss: 2.291615, Cross Entropy: 2.461136, Reg: 0.765921
Elapsed time (s): 0.01429438591003418
Memory usage (GB): 0.341033935546875
Test: 100/1000 (10%)	Loss: 2.531322, Cross Entropy: 2.417554, Reg: 3.555232
Elapsed time (s): 7.698845863342285
Memory usage (GB): 0.3628959655761719
Test: 200/1000 (20%)	Loss: 1.391469, Cross Entropy: 1.461210, Reg: 0.763792
Elapsed time (s): 6.50078272819519
Memory usage (GB): 0.3628959655761719
Test: 300/1000 (30%)	Loss: 1.494378, Cross Entropy: 1.492479, Reg: 1.511466
Elapsed time (s): 7.164916753768921
Memory usage (GB): 0.3635902404785156
Test: 400/1000 (40%)	Loss: 2.295346, Cross Entropy: 2.461046, Reg: 0.804043
Elapsed time (s): 6.350499153137207
Memory usage (GB): 0.3635902404785156
Test: 500/1000 (50%)	Loss: 2.310647, Cross Entropy: 2.460055, Reg: 0.965978
Elapsed time (s): 7.296330690383911
Memory usage (GB): 0.3635902404785156
Test: 600/1000 (60%)	Loss: 2.293679, Cross Entropy: 2.461115, Reg: 0.786758
Elapsed time (s): 7.100704193115234
Memory usage (GB): 0.3635902404785156
Test: 700/1000 (70%)	Loss: 1.443655, Cross Entropy: 1.474964, Reg: 1.161881
Elapsed time (s): 7.6501970291137695
Memory usage (GB): 0.3635902404785156
Test: 800/1000 (80%)	Loss: 2.291059, Cross Entropy: 2.461144, Reg: 0.760294
Elapsed time (s): 7.850250244140625
Memory usage (GB): 0.3635902404785156
Test: 900/1000 (90%)	Loss: 2.296615, Cross Entropy: 2.461060, Reg: 0.816615
Elapsed time (s): 7.485640048980713
Memory usage (GB): 0.3635902404785156
Test set: Average loss: 1.7111, Average cross entropy: 1.7751, Average reg: 1.1358, Accuracy: 690/1000 (69%), Robust accuracy: 613/690 (89%)

### budget 0.2

Using cpu
Using testing batch size for test loader
Using testing batch size for train loader
Loading weights
Initialization done
Start testing
Using light train loader
Test: 0/1000 (0%)	Loss: 2.291615, Cross Entropy: 2.461136, Reg: 0.765921
Elapsed time (s): 0.008905649185180664
Memory usage (GB): 0.3321380615234375
Test: 100/1000 (10%)	Loss: 2.531322, Cross Entropy: 2.417554, Reg: 3.555232
Elapsed time (s): 8.195882320404053
Memory usage (GB): 0.3547477722167969
Test: 200/1000 (20%)	Loss: 1.391469, Cross Entropy: 1.461210, Reg: 0.763792
Elapsed time (s): 6.661213397979736
Memory usage (GB): 0.3547477722167969
Test: 300/1000 (30%)	Loss: 1.494378, Cross Entropy: 1.492479, Reg: 1.511466
Elapsed time (s): 7.506087303161621
Memory usage (GB): 0.3547477722167969
Test: 400/1000 (40%)	Loss: 2.295346, Cross Entropy: 2.461046, Reg: 0.804043
Elapsed time (s): 6.326592683792114
Memory usage (GB): 0.3552513122558594
Test: 500/1000 (50%)	Loss: 2.310647, Cross Entropy: 2.460055, Reg: 0.965978
Elapsed time (s): 7.378765344619751
Memory usage (GB): 0.3552513122558594
Test: 600/1000 (60%)	Loss: 2.293679, Cross Entropy: 2.461115, Reg: 0.786758
Elapsed time (s): 7.337314605712891
Memory usage (GB): 0.3552513122558594
Test: 700/1000 (70%)	Loss: 1.443655, Cross Entropy: 1.474964, Reg: 1.161881
Elapsed time (s): 7.609984874725342
Memory usage (GB): 0.3552513122558594
Test: 800/1000 (80%)	Loss: 2.291059, Cross Entropy: 2.461144, Reg: 0.760294
Elapsed time (s): 7.790330410003662
Memory usage (GB): 0.3552513122558594
Test: 900/1000 (90%)	Loss: 2.296615, Cross Entropy: 2.461060, Reg: 0.816615
Elapsed time (s): 7.5127317905426025
Memory usage (GB): 0.3552513122558594
Test set: Average loss: 1.7111, Average cross entropy: 1.7751, Average reg: 1.1358, Accuracy: 690/1000 (69%), Robust accuracy: 223/690 (32%)

### budget 0.3

Using cpu
Using testing batch size for test loader
Using testing batch size for train loader
Loading weights
Initialization done
Start testing
Using light train loader
Test: 0/1000 (0%)	Loss: 2.291615, Cross Entropy: 2.461136, Reg: 0.765921
Elapsed time (s): 0.008890151977539062
Memory usage (GB): 0.3324089050292969
Test: 100/1000 (10%)	Loss: 2.531322, Cross Entropy: 2.417554, Reg: 3.555232
Elapsed time (s): 7.97490930557251
Memory usage (GB): 0.3484306335449219
Test: 200/1000 (20%)	Loss: 1.391469, Cross Entropy: 1.461210, Reg: 0.763792
Elapsed time (s): 6.679779529571533
Memory usage (GB): 0.3491859436035156
Test: 300/1000 (30%)	Loss: 1.494378, Cross Entropy: 1.492479, Reg: 1.511466
Elapsed time (s): 7.182679653167725
Memory usage (GB): 0.3491859436035156
Test: 400/1000 (40%)	Loss: 2.295346, Cross Entropy: 2.461046, Reg: 0.804043
Elapsed time (s): 6.784228563308716
Memory usage (GB): 0.3528900146484375
Test: 500/1000 (50%)	Loss: 2.310647, Cross Entropy: 2.460055, Reg: 0.965978
Elapsed time (s): 7.419002532958984
Memory usage (GB): 0.3528900146484375
Test: 600/1000 (60%)	Loss: 2.293679, Cross Entropy: 2.461115, Reg: 0.786758
Elapsed time (s): 7.08665919303894
Memory usage (GB): 0.3528900146484375
Test: 700/1000 (70%)	Loss: 1.443655, Cross Entropy: 1.474964, Reg: 1.161881
Elapsed time (s): 7.608654022216797
Memory usage (GB): 0.3528900146484375
Test: 800/1000 (80%)	Loss: 2.291059, Cross Entropy: 2.461144, Reg: 0.760294
Elapsed time (s): 7.794465065002441
Memory usage (GB): 0.3528900146484375
Test: 900/1000 (90%)	Loss: 2.296615, Cross Entropy: 2.461060, Reg: 0.816615
Elapsed time (s): 7.484297275543213
Memory usage (GB): 0.3528900146484375
Test set: Average loss: 1.7111, Average cross entropy: 1.7751, Average reg: 1.1358, Accuracy: 690/1000 (69%), Robust accuracy: 2/690 (0%)

# test_loader

## epoch 10

### budget 0.1

### budget 0.2

### budget 0.3


